cff-version: 1.2.0
title: "Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding"
message: "If you use this research, please cite it as below."
type: software
authors:
  - given-names: Ishraq
    family-names: Khan
    email: ishraq@kodezi.com
    affiliation: Kodezi Inc.
    orcid: 'https://orcid.org/0000-0000-0000-0000'
  - given-names: Assad
    family-names: Chowdary
    email: assad@kodezi.com
    affiliation: Kodezi Inc.
  - given-names: Sharoz
    family-names: Haseeb
    email: sharoz@kodezi.com
    affiliation: Kodezi Inc.
  - given-names: Urvish
    family-names: Patel
    email: urvish@kodezi.com
    affiliation: Kodezi Inc.
  - given-names: Yousuf
    family-names: Zaii
    email: yousuf@kodezi.com
    affiliation: Kodezi Inc.
identifiers:
  - type: doi
    value: 10.48550/arXiv.2507.12482
    description: arXiv preprint
repository-code: 'https://github.com/kodezi/chronos-research'
url: 'https://kodezi.com/chronos'
repository: 'https://arxiv.org/abs/2507.12482'
abstract: >-
  Large Language Models (LLMs) have advanced code generation and software automation,
  but are fundamentally constrained by limited inference-time context and lack of
  explicit code structure reasoning. We introduce Kodezi Chronos, a next-generation
  architecture for autonomous code understanding, debugging, and maintenance, designed
  to operate across ultra-long contexts comprising entire codebases, histories, and
  documentation—all without fixed window limits. Kodezi Chronos leverages a multi-level
  embedding memory engine, combining vector and graph-based indexing with continuous
  code-aware retrieval. This enables efficient and accurate reasoning over millions
  of lines of code, supporting repository-scale comprehension, multi-file refactoring,
  and real-time self-healing actions. Chronos achieves state-of-the-art 80.33% success
  rate on SWE-bench Lite (241/300 instances), a 20 percentage point lead over the next
  best system, and 67.3% on comprehensive debugging benchmarks—representing a 4-5x
  improvement over state-of-the-art models including Claude 4.1 Opus, Claude 4.5 Sonnet,
  and GPT-4.1.
keywords:
  - debugging
  - language models
  - code understanding
  - software engineering
  - autonomous systems
  - memory-driven AI
license: MIT
version: 2.0.0
date-released: '2025-07-29'